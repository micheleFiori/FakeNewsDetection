{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_embedding(w):\n",
    "    try:\n",
    "        e = keyed_vector[w] #.wv\n",
    "    except KeyError:\n",
    "        return None\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embedding(word_embeddings):\n",
    "    filtered = [arr for arr in word_embeddings if arr is not None]\n",
    "    if filtered:\n",
    "        return np.mean(filtered, axis=0)\n",
    "    else:\n",
    "        return -np.inf #raise ValueError(\"All the elements of the list are None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_embeddings = lambda x: [get_word_embedding(word) for word in x.split()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../dataset/prep_train.csv\")\n",
    "val = pd.read_csv(\"../dataset/prep_valid.csv\")\n",
    "test = pd.read_csv(\"../dataset/prep_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams_corpus = train.STATEMENT.apply(lambda x: x.split()).tolist()\n",
    "keyed_vector = Word2Vec(unigrams_corpus, min_count=1, workers=4, vector_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.STATEMENT.apply(get_embeddings)\n",
    "X_train = [get_sentence_embedding(x) for x in X_train]\n",
    "X_val = val.STATEMENT.apply(get_embeddings)\n",
    "X_val = [get_sentence_embedding(x) for x in X_val]\n",
    "Y_train = train.LABEL\n",
    "Y_val = val.LABEL\n",
    "X_train, Y_train = zip(*[(x, y) for x, y in zip(X_train, Y_train) if x is not None])\n",
    "X_val, Y_val = zip(*[(x, y) for x, y in zip(X_val, Y_val) if x is not None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n",
    "n_iterations = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('unigrams_svm.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for k in kernel:\n",
    "        accs = []\n",
    "        for i in range(n_iterations):\n",
    "            clf = make_pipeline(StandardScaler(), SVC(kernel=k))\n",
    "            clf.fit(X_train, Y_train)\n",
    "            accs.append(clf.score(X_val, Y_val))\n",
    "        acc = mean(accs)\n",
    "        print(f\"{k}, {acc}\")\n",
    "        data = [k, acc]\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [50, 100, 150, 200, 250]\n",
    "n_iterations = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('unigrams_rf.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for n in n_estimators:\n",
    "        accs = []\n",
    "        for i in range(n_iterations):\n",
    "            clf = RandomForestClassifier(max_depth=None, n_estimators=n)\n",
    "            clf.fit(X_train, Y_train)\n",
    "            accs.append(clf.score(X_val, Y_val))\n",
    "        acc = mean(accs)\n",
    "        print(f\"{n}, {acc}\")\n",
    "        data = [n, acc]\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyed_vector = KeyedVectors.load_word2vec_format('PreTrainedCorpus/GoogleNews/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.STATEMENT.apply(get_embeddings)\n",
    "X_train = [get_sentence_embedding(x) for x in X_train]\n",
    "X_val = val.STATEMENT.apply(get_embeddings)\n",
    "X_val = [get_sentence_embedding(x) for x in X_val]\n",
    "Y_train = train.LABEL\n",
    "Y_val = val.LABEL\n",
    "X_train, Y_train = zip(*[(x, y) for x, y in zip(X_train, Y_train) if x is not None])\n",
    "X_val, Y_val = zip(*[(x, y) for x, y in zip(X_val, Y_val) if x is not None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n",
    "n_iterations = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('svm.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for k in kernel:\n",
    "        accs = []\n",
    "        for i in range(n_iterations):\n",
    "            clf = make_pipeline(StandardScaler(), SVC(kernel=k))\n",
    "            clf.fit(X_train, Y_train)\n",
    "            accs.append(clf.score(X_val, Y_val))\n",
    "        acc = mean(accs)\n",
    "        print(f\"{k}, {acc}\")\n",
    "        data = [k, acc]\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [250, 300, 400]\n",
    "n_iterations = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rf2.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for n in n_estimators:\n",
    "        accs = []\n",
    "        for i in range(n_iterations):\n",
    "            clf = RandomForestClassifier(max_depth=None, n_estimators=n)\n",
    "            clf.fit(X_train, Y_train)\n",
    "            accs.append(clf.score(X_val, Y_val))\n",
    "        acc = mean(accs)\n",
    "        print(f\"{n}, {acc}\")\n",
    "        data = [n, acc]\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyed_vector = KeyedVectors.load_word2vec_format('PreTrainedCorpus/Glove/glove.840B.300d.txt', binary=False, no_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.STATEMENT.apply(get_embeddings)\n",
    "X_train = [get_sentence_embedding(x) for x in X_train]\n",
    "X_val = val.STATEMENT.apply(get_embeddings)\n",
    "X_val = [get_sentence_embedding(x) for x in X_val]\n",
    "Y_train = train.LABEL\n",
    "Y_val = val.LABEL\n",
    "X_train, Y_train = zip(*[(x, y) for x, y in zip(X_train, Y_train) if x is not None])\n",
    "X_val, Y_val = zip(*[(x, y) for x, y in zip(X_val, Y_val) if x is not None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n",
    "n_iterations = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('glove_svm.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for k in kernel:\n",
    "        accs = []\n",
    "        for i in range(n_iterations):\n",
    "            clf = make_pipeline(StandardScaler(), SVC(kernel=k))\n",
    "            clf.fit(X_train, Y_train)\n",
    "            accs.append(clf.score(X_val, Y_val))\n",
    "        acc = mean(accs)\n",
    "        print(f\"{k}, {acc}\")\n",
    "        data = [k, acc]\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [50, 100, 150, 200, 250]\n",
    "n_iterations = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('glove_rf.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for n in n_estimators:\n",
    "        accs = []\n",
    "        for i in range(n_iterations):\n",
    "            clf = RandomForestClassifier(max_depth=None, n_estimators=n)\n",
    "            clf.fit(X_train, Y_train)\n",
    "            accs.append(clf.score(X_val, Y_val))\n",
    "        acc = mean(accs)\n",
    "        print(f\"{n}, {acc}\")\n",
    "        data = [n, acc]\n",
    "        writer.writerow(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
